{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2cf5f9-8e95-438b-a167-99912082985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.colors as mcolors\n",
    "import pandas as pd\n",
    "\n",
    "from code_.model_activations.configs import model_cfg as cfg\n",
    "from code_.eigen_analysis.utils import *\n",
    "from code_.model_activations.loading import load_full_identifier\n",
    "\n",
    "from config import CACHE, DATA, PCA_PATH, FIGURES, RESULTS\n",
    "y_lim = {'naturalscenes':0.45, 'majajhong': 0.65, 'things':0.15}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894161c4",
   "metadata": {},
   "source": [
    "## Num PCs Required to Explain X% Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35b6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'naturalscenes'\n",
    "region = 'midventral visual stream'\n",
    "ex_var=0.85\n",
    "incremental = True\n",
    "components=7000\n",
    "\n",
    "\n",
    "dataset = 'majajhong'\n",
    "region = 'IT'\n",
    "ex_var=0.85\n",
    "incremental = False\n",
    "components=2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a29e80-bbb1-41be-b817-2699a80c4d17",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/atlas/expansion_cache/pca/expansion_features=3_layers=5_dataset=majajhong_principal_components=2000'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m incremental:\n\u001b[32m     23\u001b[39m     file_path += \u001b[33m'\u001b[39m\u001b[33m_incremental\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     26\u001b[39m     pca = pickle.load(file)\n\u001b[32m     27\u001b[39m num_components_required = num_pcs_required(pca.explained_variance_ratio_,explained_variance=ex_var)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/shared/miniconda3/envs/expansion_model/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/data/atlas/expansion_cache/pca/expansion_features=3_layers=5_dataset=majajhong_principal_components=2000'"
     ]
    }
   ],
   "source": [
    "PCA_PATH = os.path.join(CACHE, 'pca')\n",
    "\n",
    "data_dict = {'expansion':{'features':[],'num_components':[],'score':[], 'lower':[], 'upper':[]},\n",
    "           'fully_connected':{'features':[],'num_components':[],'score':[],'lower':[], 'upper':[]},\n",
    "           'vit':{'features':[],'num_components':[],'score':[], 'lower':[], 'upper':[]},\n",
    "          }\n",
    "models = ['expansion','vit', 'fully_connected']\n",
    "\n",
    "for i, model_name in enumerate(models):\n",
    "    \n",
    "    for j, f in enumerate(cfg[dataset]['models'][model_name]['features']):\n",
    "        # print(model_name, f)\n",
    "        data_dict[model_name]['features'].append(str(f))\n",
    "                    \n",
    "        iden = load_full_identifier(model_name=model_name, \n",
    "                 features=f, \n",
    "                 layers=5,\n",
    "                 principal_components=components,\n",
    "                 dataset=dataset)\n",
    "    \n",
    "        file_path = f'{PCA_PATH}/{iden}'\n",
    "        if incremental:\n",
    "            file_path += '_incremental'\n",
    "        \n",
    "        with open(file_path, 'rb') as file:\n",
    "            pca = pickle.load(file)\n",
    "        num_components_required = num_pcs_required(pca.explained_variance_ratio_,explained_variance=ex_var)\n",
    "        data_dict[model_name]['num_components'].append(num_components_required)\n",
    "        del pca\n",
    "        \n",
    "        file_name = os.path.join(RESULTS, f'bootstrap-results-{model_name}-{dataset}-{region}.csv')\n",
    "        scores = pd.read_csv(file_name)\n",
    "        scores['score'] = scores['score'].apply(lambda x: float(x.replace(\"tensor(\", \"\").replace(\")\", \"\")))\n",
    "        data_dict[model_name]['score'].append(float(scores[scores.features == f]['score'].values))\n",
    "        data_dict[model_name]['lower'].append(float(scores[scores.features == f]['lower'].values))\n",
    "        data_dict[model_name]['upper'].append(float(scores[scores.features == f]['upper'].values))\n",
    "        del scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982f15b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m         df = data.copy()\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     13\u001b[39m         \u001b[38;5;66;03m# assume list of dicts or dict of lists\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     data_dict[key] = df\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# ——— Flatten any list/array entries to scalars ———————————————————————————————\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/shared/miniconda3/envs/expansion_model/lib/python3.12/site-packages/pandas/core/frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/shared/miniconda3/envs/expansion_model/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/shared/miniconda3/envs/expansion_model/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/shared/miniconda3/envs/expansion_model/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = (7, 7)\n",
    "line_colors = {\n",
    "    'expansion':       'royalblue',\n",
    "    'vit':             'palevioletred',\n",
    "    'fully_connected': 'darkviolet'\n",
    "}\n",
    "\n",
    "# ——— Convert each entry in data_dict into a DataFrame —————————————————————————\n",
    "for key, data in list(data_dict.items()):\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        df = data.copy()\n",
    "    else:\n",
    "        # assume list of dicts or dict of lists\n",
    "        df = pd.DataFrame(data)\n",
    "    data_dict[key] = df\n",
    "\n",
    "# ——— Flatten any list/array entries to scalars ———————————————————————————————\n",
    "for key, df in data_dict.items():\n",
    "    for col in ['score', 'lower', 'upper']:\n",
    "        # If the column contains lists/arrays, take their mean; else cast to float\n",
    "        df[col] = df[col].apply(\n",
    "            lambda v: float(np.mean(v)) if isinstance(v, (list, np.ndarray)) else float(v)\n",
    "        )\n",
    "    data_dict[key] = df  # overwrite with cleaned DataFrame\n",
    "\n",
    "# ——— Create figure & axis —————————————————————————————————————————————————\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "def plot_series(key, label):\n",
    "    \"\"\"Plot one line with its error bars.\"\"\"\n",
    "    df = data_dict[key]\n",
    "    # Plot main line\n",
    "    sns.lineplot(\n",
    "        x='num_components',\n",
    "        y='score',\n",
    "        data=df,\n",
    "        color=line_colors[key],\n",
    "        label=label,\n",
    "        ax=ax,\n",
    "        ci=None\n",
    "    )\n",
    "    # Compute error magnitudes\n",
    "    lower_err = df['score'] - df['lower']\n",
    "    upper_err = df['upper'] - df['score']\n",
    "    print(lower_err)\n",
    "    print(upper_err)\n",
    "    # Add vertical error bars\n",
    "    ax.errorbar(\n",
    "        df['num_components'],\n",
    "        df['score'],\n",
    "        yerr=[lower_err.values, upper_err.values],\n",
    "        fmt='none',\n",
    "        ecolor=line_colors[key],\n",
    "        capsize=3\n",
    "    )\n",
    "\n",
    "# ——— Plot each condition ————————————————————————————————————————————————\n",
    "plot_series('expansion',       'Expansion')\n",
    "plot_series('vit',             'ViT')\n",
    "plot_series('fully_connected', 'Fully Connected')\n",
    "\n",
    "# ——— Final formatting ——————————————————————————————————————————————————\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Number of Principal Components', size=15)\n",
    "ax.set_ylabel('Score', size=15)\n",
    "ax.tick_params(labelsize=15)\n",
    "ax.set_title(f'{int(ex_var*100)}% Variance – Region: {region}', size=20)\n",
    "\n",
    "# Legend only if region == 'V4'\n",
    "if region == 'V4':\n",
    "    ax.legend()\n",
    "else:\n",
    "    ax.get_legend().remove()\n",
    "plt.ylim(0,y_lim[dataset])\n",
    "\n",
    "# ——— Save & display ———————————————————————————————————————————————————\n",
    "output_path = os.path.join(\n",
    "    FIGURES,\n",
    "    f'figure_S5_{dataset}_{region}_var={ex_var:.2f}.png'\n",
    ")\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d4f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expansion_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
