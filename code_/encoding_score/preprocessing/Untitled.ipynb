{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17c203c7-59d8-4204-9e18-211faaac4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_center_data(X):\n",
    "    \"\"\"\n",
    "    Mean centers the features (X) and target (y) data.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy.ndarray): The feature data.\n",
    "    y (numpy.ndarray): The target data.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray, numpy.ndarray: Mean-centered feature and target data.\n",
    "    \"\"\"\n",
    "    X_mean = X.mean(axis=0)\n",
    "    X_centered = X - X_mean\n",
    "\n",
    "    return X_centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4849c7a7-274b-4183-a5a9-e15bd7cb0bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def preprocess_data(X, y, center='none', scale='none', output=None, fit_intercept=False):\n",
    "    stats = {f'{var}_{stat}': None for stat in ['mean','std','offset','scale'] for var in ['X', 'y']}\n",
    "\n",
    "    def parse_preprocessing_args(*args):\n",
    "        parsed_args = []\n",
    "        for arg in args:\n",
    "            if arg is None or len(arg) == 0:\n",
    "                parsed_args.append('none')\n",
    "            elif isinstance(arg, list):\n",
    "                parsed_args.append(''.join(arg))\n",
    "            else:\n",
    "                parsed_args.append(arg)\n",
    "        return tuple(parsed_args)\n",
    "\n",
    "    center, scale, output = parse_preprocessing_args(center, scale, output)\n",
    "    \n",
    "    if fit_intercept:\n",
    "        center += 'x'\n",
    "\n",
    "    if 'x' in center.lower():\n",
    "        stats['X_mean'] = X.mean(dim = 0)\n",
    "    if 'y' in center.lower():\n",
    "        stats['y_mean'] = y.mean(dim = 0) if y.ndim > 1 else y.mean()\n",
    "        \n",
    "    if 'x' in scale.lower():\n",
    "        stats['X_std'] = X.std(dim=0, correction=1)\n",
    "        stats['X_std'][stats['X_std'] == 0.0] = 1.0  \n",
    "    if 'y' in scale.lower():\n",
    "        stats['y_std'] = y.std(dim=0, correction=1)\n",
    "        stats['y_std'][stats['y_std'] == 0.0] = 1.0 \n",
    "    \n",
    "    if 'x' in center.lower():\n",
    "        X -= stats['X_mean']\n",
    "    if 'y' in center.lower():\n",
    "        y -= stats['y_mean']\n",
    "        \n",
    "    if 'x' in scale.lower():\n",
    "        X /= stats['X_std']\n",
    "    if 'y' in scale.lower():\n",
    "        y /= stats['y_std']\n",
    "\n",
    "    if output == 'mean_std':\n",
    "        if stats['X_mean'] is None:\n",
    "            stats['X_mean'] = X.mean(dim=0)\n",
    "        if stats['y_mean'] is None:\n",
    "            stats['y_mean'] = y.mean(dim = 0) if y.ndim > 1 else y.mean()\n",
    "        if stats['X_std'] is None:\n",
    "            stats['X_std'] = torch.ones(X.shape[1], dtype=X.dtype,  device=X.device)\n",
    "        if stats['y_std'] is None:\n",
    "            stats['y_std'] = torch.ones(y.shape[1], dtype=y.dtype,  device=y.device)\n",
    "\n",
    "    if output == 'offset_scale':\n",
    "        stats['X_offset'] = stats.pop('X_mean', None)\n",
    "        stats['y_offset'] = stats.pop('y_mean', None)\n",
    "        stats['X_scale'] = stats.pop('X_std', None)\n",
    "        if stats['X_offset'] is None:\n",
    "            stats['X_offset'] = torch.zeros(X.shape[1], dtype=X.dtype, device=X.device)\n",
    "        if stats['y_offset'] is None:\n",
    "            stats['y_offset'] = torch.zeros(y.shape[1], dtype=y.dtype, device=y.device)\n",
    "        if stats['X_scale'] is None:\n",
    "            stats['X_scale'] = torch.ones(X.shape[1], dtype=X.dtype,  device=X.device)\n",
    "\n",
    "    if output == 'offset_scale':\n",
    "        return X, y, stats['X_offset'], stats['y_offset'], stats['X_scale']\n",
    "\n",
    "    if output == 'mean_std':\n",
    "        return X, y, stats['X_mean'], stats['y_mean'], stats['X_std'], stats['y_std']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Example usage\n",
    "# X, y = ... # your data here\n",
    "# X_preprocessed, y_preprocessed = preprocess_data(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4f1847a-7095-47fb-a659-35d982917d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import random \n",
    "from tqdm import tqdm \n",
    "import pickle \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random    \n",
    "random.seed(0)\n",
    "import scipy.stats as st\n",
    "import gc\n",
    "\n",
    "ROOT = os.getenv('BONNER_ROOT_PATH')\n",
    "sys.path.append(ROOT)\n",
    "from config import CACHE, NSD_NEURAL_DATA, NSD_SAMPLE_IMAGES    \n",
    "from model_evaluation.predicting_brain_data.benchmarks.nsd_old import filter_activations\n",
    "from model_evaluation.predicting_brain_data.regression.regression import regression_shared_unshared, pearson_r\n",
    "from model_evaluation.predicting_brain_data.regression.torch_cv import TorchRidgeGCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "SHARED_IDS_PATH = os.path.join(ROOT, 'image_tools','nsd_ids_shared')\n",
    "SHARED_IDS = pickle.load(open(SHARED_IDS_PATH, 'rb'))\n",
    "SHARED_IDS = [image_id.strip('.png') for image_id in SHARED_IDS]\n",
    "\n",
    "SAMPLE_IDS = pickle.load(open(NSD_SAMPLE_IMAGES, 'rb'))\n",
    "SAMPLE_IDS = [image_id.strip('.png') for image_id in SAMPLE_IDS]\n",
    "\n",
    "ALPHA_RANGE = [10**i for i in range(10)]\n",
    "    \n",
    "    \n",
    "def normalize(X):\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "def load_nsd_data(mode: str, subject: int, region: str, return_data:bool=True) -> torch.Tensor:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        Loads the neural data from disk for a particular subject and region.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mode:\n",
    "            The type of neural data to load ('shared' or 'unshared')\n",
    "            \n",
    "        subject:\n",
    "            The subject number \n",
    "        \n",
    "        region:\n",
    "            The region name\n",
    "            \n",
    "        return_ids: \n",
    "            Whether the image ids are returned \n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A Tensor of Neural data, or Tensor of Neural data and stimulus ids\n",
    "        \n",
    "        \"\"\"\n",
    "        path = os.path.join(NSD_NEURAL_DATA,f'roi={region}/preprocessed/z_score=session.average_across_reps=True/subject={subject}.nc')\n",
    "        \n",
    "        var_name = f'allen2021.natural_scenes.preprocessing=fithrf_GLMdenoise_RR.roi={region}.z_score=session.average_across_reps=True.subject={subject}'\n",
    "\n",
    "        \n",
    "        ds = xr.open_dataset(path, engine='h5netcdf')\n",
    "\n",
    "        if mode == 'unshared':\n",
    "            data = ds.where(~ds.presentation.stimulus_id.isin(SHARED_IDS),drop=True)\n",
    "\n",
    "        elif mode == 'shared':\n",
    "            data = ds.where(ds.presentation.stimulus_id.isin(SHARED_IDS),drop=True)\n",
    "                        \n",
    "        ids = list(data.presentation.stimulus_id.values)\n",
    "            \n",
    "        if return_data:\n",
    "            return ids, data, var_name\n",
    "        \n",
    "        else: \n",
    "            return ids\n",
    "        \n",
    "        \n",
    "            \n",
    "def filter_activations(data: xr.DataArray, ids: list) -> torch.Tensor:\n",
    "            \n",
    "        \"\"\"\n",
    "    \n",
    "        Filters model activations using image ids.\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data:\n",
    "            Model activation data\n",
    "            \n",
    "        ids:\n",
    "            image ids\n",
    "        \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A Tensor of model activations filtered by image ids\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        data = data.set_index({'presentation':'stimulus_id'})\n",
    "        activations = data.sel(presentation=ids)\n",
    "        activations = activations.sortby('presentation', ascending=True)\n",
    "\n",
    "        return activations.values\n",
    "    \n",
    "    \n",
    "def normalize(X):\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    X = np.nan_to_num(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4955c294-6055-4f56-ad09-eef3eb1b228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "region='V1'\n",
    "subject = 0\n",
    "device = 'cpu'\n",
    "activations_identifier= f'expansion_30_dataset=naturalscenes_subject={subject}'\n",
    "\n",
    "#load X_train and y_train\n",
    "activations_train = xr.open_dataset(os.path.join(CACHE,'activations', activations_identifier))\n",
    "activations_test= xr.open_dataset(os.path.join(CACHE,'activations',f'expansion_30_dataset=naturalscenes_shared_images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ffca49a2-1a81-4e93-b6d4-85758d8730e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xr.concat([activations_train,activations_test],dim='presentation')\n",
    "X.x.values = mean_center_data(X.x.values)\n",
    "ids_train = load_nsd_data(mode = 'unshared', subject = subject, region = region,return_data=False)\n",
    "ids_test = load_nsd_data(mode ='shared',subject = subject,region = region, return_data=False)    \n",
    "\n",
    "X_train = filter_activations(X, ids_train)\n",
    "X_test = filter_activations(X, ids_test)\n",
    "\n",
    "X = X.set_index({'presentation':'stimulus_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b5801797-b0ba-450e-9be8-30ec23023b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.sel(presentation=ids_train).x.values\n",
    "X_test = X.sel(presentation=ids_test).x.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04b0c296-240b-43df-9ec0-65b428415d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ , neural_data_train, var_name_train = load_nsd_data(mode = 'unshared', subject = subject, region = region)\n",
    "y_train = neural_data_train[var_name_train].values\n",
    "\n",
    "_ , neural_data_test, var_name_test = load_nsd_data(mode ='shared',subject = subject,region = region)     \n",
    "y_test = neural_data_test[var_name_test].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "132c0a35-d3ee-427c-91e8-1f77cde0df59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha: 1.0\n",
      "best score: tensor(0.4173)\n"
     ]
    }
   ],
   "source": [
    "# corss validated ridge regression on training data to find optimal penalty term\n",
    "regression = TorchRidgeGCV(\n",
    "    alphas=ALPHA_RANGE,\n",
    "    fit_intercept=True,\n",
    "    scale_X=False,\n",
    "    scoring='pearsonr',\n",
    "    store_cv_values=False,\n",
    "    alpha_per_target=False,\n",
    "    device=device)\n",
    "\n",
    "#regression.to('cpu')\n",
    "regression.fit(X_train, y_train)\n",
    "best_alpha = float(regression.alpha_)\n",
    "print('best alpha:',best_alpha)\n",
    "print('best score:',regression.score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0fd2f32-62f2-41a1-81c8-6b1ef0793972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "from torchmetrics.functional import spearman_corrcoef, pearson_corrcoef\n",
    "from torchmetrics.functional import concordance_corrcoef, explained_variance\n",
    "\n",
    "def preprocess_data(X, y, center='x', scale='x', output='offset_scale', fit_intercept=True):\n",
    "    X_mean, X_std, y_mean, y_std = X.mean(0), X.std(0), y.mean(0), y.std(0)\n",
    "    X_std[X_std == 0] = 1\n",
    "    y_std[y_std == 0] = 1\n",
    "    \n",
    "    if fit_intercept:\n",
    "        X = (X - X_mean) / X_std\n",
    "        y = (y - y_mean) / y_std\n",
    "\n",
    "    if output == 'offset_scale':\n",
    "        return X, y, X_mean, y_mean, X_std, y_std\n",
    "    return X, y\n",
    "\n",
    "def convert_to_tensor(*args, device='cpu'):\n",
    "    result = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, np.ndarray):\n",
    "            arg = torch.from_numpy(arg).to(device)\n",
    "        elif isinstance(arg, cp.ndarray):\n",
    "            arg = cp.asnumpy(arg)\n",
    "            arg = torch.from_numpy(arg).to(device)\n",
    "        result.append(arg)\n",
    "    return result\n",
    "\n",
    "def unify_dtypes(*args, target_dtype=torch.float32):\n",
    "    return tuple(arg.to(target_dtype) for arg in args if isinstance(arg, torch.Tensor))\n",
    "\n",
    "def get_scorer(score_type):\n",
    "    _score_functions = {\n",
    "        'spearmanr': spearman_corrcoef,\n",
    "        'pearsonr': pearson_corrcoef,\n",
    "        'concordance': concordance_corrcoef,\n",
    "        'explained_variance': explained_variance\n",
    "    }\n",
    "    return _score_functions[score_type]\n",
    "\n",
    "def ridge_regression_custom(alpha, X_train, y_train, X_test, y_test, fit_intercept=True, scale_X=True, scoring='pearsonr'):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    # Preprocess data\n",
    "    X_train, y_train, _, _, _, _ = preprocess_data(X_train, y_train, fit_intercept=fit_intercept, scale=scale_X)\n",
    "    X_test, y_test = preprocess_data(X_test, y_test, fit_intercept=False, scale=False)[0:2]\n",
    "\n",
    "    # Convert data to tensor\n",
    "    X_train, y_train, X_test, y_test = convert_to_tensor(X_train, y_train, X_test, y_test, device=device)\n",
    "    X_train, y_train, X_test, y_test = unify_dtypes(X_train, y_train, X_test, y_test)\n",
    "\n",
    "    # Ridge regression using normal equation\n",
    "    I = torch.eye(X_train.size(1), device=device)\n",
    "    beta = torch.linalg.inv(X_train.T @ X_train + alpha * I) @ X_train.T @ y_train\n",
    "\n",
    "    # Predictions on the test set\n",
    "    y_pred = X_test @ beta\n",
    "\n",
    "    # Scoring\n",
    "    scorer = get_scorer(scoring)\n",
    "\n",
    "    return y_pred.cpu().numpy()\n",
    "\n",
    "# Example usage:\n",
    "# alpha = 1.0\n",
    "# X_train = np.array([...])\n",
    "# y_train = np.array([...])\n",
    "# X_test = np.array([...])\n",
    "# y_test = np.array([...])\n",
    "# y_predicted, score = ridge_regression_custom(alpha, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e2a74e3a-8dbf-48e8-a15d-5df4ac768742",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_regression_custom(1000000, X_train, y_train, X_test, y_test, fit_intercept=True, scale_X=False, scoring='pearsonr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "260247df-50e1-451b-a433-7935c813fa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1909)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model= Ridge(alpha=1000000)\n",
    "# model.fit(X_train, y_train)\n",
    "# y_predicted = regression.predict(X_test)\n",
    "r = pearson_r(torch.Tensor(y_test),torch.Tensor(y_pred))\n",
    "r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9cdd2-2f2b-43ae-88ec-78fdc1354bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
